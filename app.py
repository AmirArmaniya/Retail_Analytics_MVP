import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import tempfile
import math
from collections import deque

st.set_page_config(page_title="Stitched Counter", layout="wide")
st.title("ğŸ§µ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª ØªØ±Ù…ÛŒÙ… Ù…Ø³ÛŒØ± (Track Stitching)")
st.caption("Ø­Ù„ Ù…Ø´Ú©Ù„ 'Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø´Ù…Ø±Ø¯Ù†' Ø¨Ø§ ÙˆØµÙ„ Ú©Ø±Ø¯Ù† Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù‚Ø·Ø¹ Ø´Ø¯Ù‡.")

# --- Ø§Ø³ØªØ§ÛŒÙ„ CSS Ø¨Ø±Ø§ÛŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ ---
st.markdown("""
<style>
    div[data-testid="stMetricValue"] { font-size: 30px; color: #00FF00; }
</style>
""", unsafe_allow_html=True)

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± ---
with st.sidebar:
    st.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙˆØ±ÙˆØ¯ÛŒ")
    uploaded_file = st.file_uploader("ÙØ§ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆ", type=["mp4", "avi", "mov"])
    
    st.divider()
    st.header("ğŸ›  ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø®Ø· Ú¯ÛŒØª")
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø®Ø·
    col_a1, col_a2 = st.columns(2)
    with col_a1: line_x1 = st.slider("X Ø´Ø±ÙˆØ¹ (%)", 0, 100, 10)
    with col_a2: line_y1 = st.slider("Y Ø´Ø±ÙˆØ¹ (%)", 0, 100, 50)
    col_b1, col_b2 = st.columns(2)
    with col_b1: line_x2 = st.slider("X Ù¾Ø§ÛŒØ§Ù† (%)", 0, 100, 90)
    with col_b2: line_y2 = st.slider("Y Ù¾Ø§ÛŒØ§Ù† (%)", 0, 100, 50)

    st.divider()
    st.header("ğŸ§  ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…ØºØ² (Stitcher)")
    st.info("Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¬Ø§Ø¯ÙˆÛŒ Ø§ØµÙ„ÛŒ Ø§Ø³Øª:")
    # ÙØ§ØµÙ„Ù‡ Ù…Ø¬Ø§Ø² Ø¨Ø±Ø§ÛŒ ÙˆØµÙ„ Ú©Ø±Ø¯Ù† Ø¯Ùˆ Ù…Ø³ÛŒØ±
    stitch_dist = st.slider("ÙØ§ØµÙ„Ù‡ Ø¨Ø®ÛŒÙ‡ (Ù¾ÛŒÚ©Ø³Ù„)", 10, 200, 100, help="Ø§Ú¯Ø± ÙØ±Ø¯ Ø¬Ø¯ÛŒØ¯ Ø¯Ø± Ø§ÛŒÙ† ÙØ§ØµÙ„Ù‡ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ù…Ú©Ø§Ù† ÙØ±Ø¯ Ú¯Ù… Ø´Ø¯Ù‡ Ø¸Ø§Ù‡Ø± Ø´Ø¯ØŒ ÙˆØµÙ„Ø´ Ú©Ù†.")
    # Ø²Ù…Ø§Ù† Ù…Ø¬Ø§Ø² Ø¨Ø±Ø§ÛŒ ÙˆØµÙ„ Ú©Ø±Ø¯Ù†
    stitch_time = st.slider("Ø­Ø§ÙØ¸Ù‡ Ø¨Ø®ÛŒÙ‡ (ÙØ±ÛŒÙ…)", 5, 100, 45, help="ØªØ§ Ú†Ù†Ø¯ ÙØ±ÛŒÙ… Ù…Ù†ØªØ¸Ø± Ø¨Ø§Ø²Ú¯Ø´Øª ÙØ±Ø¯ Ú¯Ù… Ø´Ø¯Ù‡ Ø¨Ù…Ø§Ù†Ù…ØŸ")
    confidence = st.slider("Ø¯Ù‚Øª ØªØ´Ø®ÛŒØµ", 0.1, 0.9, 0.25)

# Ù„ÙˆØ¯ Ù…Ø¯Ù„
@st.cache_resource
def load_model():
    return YOLO('yolov8n.pt')

try:
    model = load_model()
except:
    st.error("Error loading model")

# ØªÙˆØ§Ø¨Ø¹ Ø±ÛŒØ§Ø¶ÛŒ
def ccw(A, B, C):
    return (C[1]-A[1]) * (B[0]-A[0]) > (B[1]-A[1]) * (C[0]-A[0])

def intersect(A, B, C, D):
    return ccw(A,C,D) != ccw(B,C,D) and ccw(A,B,C) != ccw(A,B,D)

def get_distance(p1, p2):
    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)

# --- Ø¨Ø¯Ù†Ù‡ Ø§ØµÙ„ÛŒ ---
col1, col2 = st.columns([3, 1])
with col2:
    st.markdown("### Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ")
    kpi_total = st.empty()
    st.divider()
    kpi_stitched = st.empty() # Ù†Ù…Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ø¯ÙØ¹Ø§ØªÛŒ Ú©Ù‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù…Ø³ÛŒØ± Ø±Ø§ Ø§ØµÙ„Ø§Ø­ Ú©Ø±Ø¯

image_placeholder = col1.empty()

if uploaded_file is not None:
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    tfile.write(uploaded_file.read())
    video_path = tfile.name
    tfile.close()

    cap = cv2.VideoCapture(video_path)
    stop = st.button("â›” ØªÙˆÙ‚Ù")

    # --- Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ---
    # ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…Ø³ÛŒØ± Ø¢ÛŒØ¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„: {id: [pos1, pos2, ...]}
    active_tracks = {}
    
    # Ù„ÛŒØ³Øª Ø§Ø±ÙˆØ§Ø­ (Ø§ÙØ±Ø§Ø¯ Ú¯Ù… Ø´Ø¯Ù‡): {old_id: {'last_pos': (x,y), 'frames_lost': 0}}
    ghost_tracks = {}
    
    # Ø¢ÛŒØ¯ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø´Ù…Ø§Ø±Ø´ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
    counted_ids = set()
    
    total_count = 0
    stitched_count = 0 # Ú†Ù†Ø¯ Ø¨Ø§Ø± Ø¢ÛŒØ¯ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø§ØµÙ„Ø§Ø­ Ú©Ø±Ø¯ÛŒÙ…ØŸ
    
    # Ù…Ù¾ ØªØ¨Ø¯ÛŒÙ„ Ø¢ÛŒØ¯ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ù‚Ø¯ÛŒÙ…: {new_id: old_id}
    id_map = {}

    frame_idx = 0
    while cap.isOpened():
        if stop: break
        ret, frame = cap.read()
        if not ret: break
        frame_idx += 1
        
        h, w, _ = frame.shape
        
        # Ø®Ø· Ú¯ÛŒØª (ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø±ØµØ¯ Ø¨Ù‡ Ù¾ÛŒÚ©Ø³Ù„)
        G1 = (int(w * line_x1 / 100), int(h * line_y1 / 100))
        G2 = (int(w * line_x2 / 100), int(h * line_y2 / 100))
        
        cv2.line(frame, G1, G2, (255, 0, 0), 2) # Ø®Ø· Ø¢Ø¨ÛŒ

        # Ù¾Ø±Ø¯Ø§Ø²Ø´ YOLO
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² bytetrack Ú†ÙˆÙ† Ù¾Ø§ÛŒØ¯Ø§Ø± Ø§Ø³ØªØŒ Ù…Ø§ Ø®ÙˆØ¯Ù…Ø§Ù† stitch Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…
        results = model.track(frame, persist=True, classes=[0], conf=confidence, tracker="bytetrack.yaml", verbose=False, device='cpu')
        
        current_frame_raw_ids = set()

        if results[0].boxes.id is not None:
            boxes = results[0].boxes.xywh.cpu().numpy()
            track_ids = results[0].boxes.id.cpu().numpy().astype(int)

            for box, raw_id in zip(boxes, track_ids):
                # 1. Ø¢ÛŒØ§ Ø§ÛŒÙ† Ø¢ÛŒØ¯ÛŒ Ø¯Ø± Ù…Ù¾ Ù…Ø§ Ù‡Ø³ØªØŸ (ÛŒØ¹Ù†ÛŒ Ù‚Ø¨Ù„Ø§ Ø¨Ø®ÛŒÙ‡ Ø®ÙˆØ±Ø¯Ù‡ØŸ)
                real_id = id_map.get(raw_id, raw_id)
                current_frame_raw_ids.add(raw_id)
                
                x, y, wb, hb = box
                center = (int(x), int(y + hb/2)) # Ù¾Ø§Ù‡Ø§

                # 2. Ø§Ú¯Ø± Ø¢ÛŒØ¯ÛŒ Ú©Ø§Ù…Ù„Ø§ Ø¬Ø¯ÛŒØ¯ Ø§Ø³ØªØŒ Ú†Ú© Ú©Ù† Ø¨Ø¨ÛŒÙ† Ø´Ø¨ÛŒÙ‡ Ø§Ø±ÙˆØ§Ø­ Ù‡Ø³ØªØŸ
                if real_id not in active_tracks:
                    # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ø§Ø±ÙˆØ§Ø­
                    best_match = None
                    min_dist = float('inf')
                    
                    for ghost_id, ghost_data in ghost_tracks.items():
                        dist = get_distance(center, ghost_data['last_pos'])
                        if dist < stitch_dist: # Ø§Ú¯Ø± Ù†Ø²Ø¯ÛŒÚ© Ø¨ÙˆØ¯
                            if dist < min_dist:
                                min_dist = dist
                                best_match = ghost_id
                    
                    if best_match is not None:
                        # ÛŒØ§ÙØª Ø´Ø¯! Ø¨Ø®ÛŒÙ‡ Ø¨Ø²Ù†
                        id_map[raw_id] = best_match # Ø§Ø² Ø§ÛŒÙ† Ø¨Ù‡ Ø¨Ø¹Ø¯ Ù‡Ø± ÙˆÙ‚Øª raw_id Ø§ÙˆÙ…Ø¯ØŒ Ø¨Ú©Ù†Ø´ best_match
                        real_id = best_match
                        del ghost_tracks[best_match] # Ø²Ù†Ø¯Ù‡ Ø´Ø¯ØŒ Ø§Ø² Ø§Ø±ÙˆØ§Ø­ Ù¾Ø§Ú©Ø´ Ú©Ù†
                        stitched_count += 1
                        # Ø§ÙÚ©Øª Ø¨ØµØ±ÛŒ Ø¨Ø®ÛŒÙ‡
                        cv2.circle(frame, center, 20, (255, 255, 255), 3) 
                
                # 3. Ø¢Ù¾Ø¯ÛŒØª Ù…Ø³ÛŒØ±
                if real_id not in active_tracks:
                    active_tracks[real_id] = []
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†Ù‚Ø·Ù‡ Ø¬Ø¯ÛŒØ¯
                active_tracks[real_id].append(center)
                if len(active_tracks[real_id]) > 30: # ÙÙ‚Ø· Û³Û° Ù†Ù‚Ø·Ù‡ Ø¢Ø®Ø±
                    active_tracks[real_id].pop(0)
                
                # 4. Ø¨Ø±Ø±Ø³ÛŒ Ø´Ù…Ø§Ø±Ø´ (ØªÙ‚Ø§Ø·Ø¹ Ø¨Ø±Ø¯Ø§Ø±)
                if len(active_tracks[real_id]) >= 2:
                    prev_pos = active_tracks[real_id][-2]
                    curr_pos = center
                    
                    # Ø´Ø±Ø· Ø´Ù…Ø§Ø±Ø´: Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§ Ø´Ù…Ø±Ø¯Ù‡ Ù†Ø´Ø¯Ù‡ Ùˆ Ø®Ø· Ø±Ø§ Ù‚Ø·Ø¹ Ú©Ø±Ø¯Ù‡
                    if real_id not in counted_ids:
                        if intersect(G1, G2, prev_pos, curr_pos):
                            total_count += 1
                            counted_ids.add(real_id)
                            # Ø§ÙÚ©Øª Ø³Ø¨Ø² Ø¹Ø¨ÙˆØ±
                            cv2.line(frame, G1, G2, (0, 255, 0), 4)

                # Ø±Ø³Ù… Ú¯Ø±Ø§ÙÛŒÚ©
                color = (0, 255, 0) if real_id in counted_ids else (0, 165, 255)
                cv2.circle(frame, center, 5, color, -1)
                # Ù†Ù…Ø§ÛŒØ´ ID Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯ (Ø¢ÛŒØ¯ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ)
                # cv2.putText(frame, str(real_id), center, cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

        # 5. Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ø±ÙˆØ§Ø­ (Ú©Ø³Ø§Ù†ÛŒ Ú©Ù‡ Ø¯Ø± Ø§ÛŒÙ† ÙØ±ÛŒÙ… ØºÛŒØ¨ Ø´Ø¯Ù†Ø¯)
        # Ø¢ÛŒØ¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ù„ÛŒ (Ø¨Ø¹Ø¯ Ø§Ø² Ù…Ù¾ Ø´Ø¯Ù†)
        current_active_real_ids = set([id_map.get(rid, rid) for rid in current_frame_raw_ids])
        
        # Ú†Ú© Ú©Ù† Ú†Ù‡ Ú©Ø³ÛŒ Ù‚Ø¨Ù„Ø§ Ø¨ÙˆØ¯Ù‡ ÙˆÙ„ÛŒ Ø§Ù„Ø§Ù† Ù†ÛŒØ³Øª
        for tid in list(active_tracks.keys()):
            if tid not in current_active_real_ids:
                # Ø§ÛŒÙ† ÙØ±Ø¯ ØºÛŒØ¨ Ø´Ø¯ -> ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø±ÙˆØ­ Ø´ÙˆØ¯
                last_known_pos = active_tracks[tid][-1]
                ghost_tracks[tid] = {'last_pos': last_known_pos, 'frames_lost': 0}
                del active_tracks[tid] # Ø§Ø² Ù„ÛŒØ³Øª ÙØ¹Ø§Ù„ Ø­Ø°Ù Ú©Ù†

        # 6. Ú©Ø§Ù‡Ø´ Ø¹Ù…Ø± Ø§Ø±ÙˆØ§Ø­
        dead_ghosts = []
        for gid in ghost_tracks:
            ghost_tracks[gid]['frames_lost'] += 1
            if ghost_tracks[gid]['frames_lost'] > stitch_time:
                dead_ghosts.append(gid)
        
        for gid in dead_ghosts:
            del ghost_tracks[gid]

        # Ù†Ù…Ø§ÛŒØ´
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image_placeholder.image(rgb_frame, channels="RGB", use_column_width=True)
        
        kpi_total.metric("ğŸ‘¥ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø´ØªØ±ÛŒØ§Ù†", total_count)
        kpi_stitched.metric("ğŸ”§ ØªØ¹Ø¯Ø§Ø¯ ØªØ¹Ù…ÛŒØ± Ù…Ø³ÛŒØ± (Stitches)", stitched_count, help="ØªØ¹Ø¯Ø§Ø¯ Ø¯ÙØ¹Ø§ØªÛŒ Ú©Ù‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙÙ‡Ù…ÛŒØ¯ Ù…Ø´ØªØ±ÛŒ Ø¬Ø¯ÛŒØ¯ØŒ Ù‡Ù…Ø§Ù† Ù…Ø´ØªØ±ÛŒ Ù‚Ø¨Ù„ÛŒ Ø§Ø³Øª.")

    cap.release()
    try: os.unlink(video_path)
    except: pass